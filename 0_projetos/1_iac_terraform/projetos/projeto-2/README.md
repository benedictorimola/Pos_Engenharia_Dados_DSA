### **Projeto 2 - Stack de Treinamento Distribu√≠do de Machine Learning com PySpark no Amazon EMR**  

### ‚ö†Ô∏è **IMPORTANTE: Este projeto gera cobran√ßa na AWS**

O **Projeto 2** tem como objetivo a implementa√ß√£o e deploy de um **stack avan√ßado de treinamento distribu√≠do de Machine Learning** utilizando **PySpark** no **Amazon Elastic MapReduce (EMR)**. A proposta √© otimizar o processamento distribu√≠do para treinar modelos em larga escala, reduzindo o tempo de treinamento e maximizando o uso de recursos.  

A estrutura do projeto inclui a **configura√ß√£o de um cluster EMR**, projetado para **execu√ß√£o eficiente de tarefas de Machine Learning distribu√≠das**. A solu√ß√£o √© escal√°vel e resiliente, aproveitando os servi√ßos da AWS para **gerenciamento de recursos e monitoramento**. O **deploy automatizado** e a **integra√ß√£o cont√≠nua** s√£o garantidos por scripts e templates de **Infraestrutura como C√≥digo (IaC)**, assegurando **replicabilidade e consist√™ncia do ambiente**.  

Al√©m do aspecto t√©cnico, o projeto adota **melhores pr√°ticas de Ci√™ncia de Dados**, cobrindo desde **prepara√ß√£o de dados** at√© **sele√ß√£o e avalia√ß√£o de modelos** em um contexto distribu√≠do. A solu√ß√£o desenvolvida permite o treinamento eficiente de modelos em **grandes volumes de dados (escala petabyte)**, sendo ideal para organiza√ß√µes que buscam **insights profundos a partir de Big Data**.  

Os dados utilizados no projeto foram preparados com base no conjunto de dados dispon√≠vel em:  
üîó [Stanford Sentiment Dataset](https://ai.stanford.edu/~amaas/data/sentiment) üöÄ


## **1. Recursos Terraform Utilizados no Projeto**

### **1.1. Seguran√ßa e Rede**  
- `aws_security_group`  
  - **main_security_group** (Grupo de seguran√ßa principal)  
  - **core_security_group** (Grupo de seguran√ßa para os n√≥s do cluster)  

### **1.2. Cluster EMR**  
- `aws_emr_cluster`  
  - **cluster** (Provisionamento do cluster no AWS EMR)  

### **1.3. Gerenciamento de Identidade e Acesso (IAM)**  
- `aws_iam_role`  
  - **iam_emr_service_role** (Papel IAM para o servi√ßo EMR)  
  - **iam_emr_profile_role** (Papel IAM para inst√¢ncias EC2 no cluster)  
- `aws_iam_instance_profile`  
  - **emr_profile** (Perfil de inst√¢ncia associado ao cluster EMR)  

### **1.4. Armazenamento S3**  
- `aws_s3_bucket`  
  - **create_bucket** (Bucket S3 para armazenamento dos dados do projeto)  
- `aws_s3_bucket_versioning`  
  - **versioning_bucket** (Configura√ß√£o de versionamento para o bucket)  
- `aws_s3_bucket_public_access_block`  
  - **example** (Bloqueio de acesso p√∫blico ao bucket S3)  

#### **1.4.1. Armazenamento S3**  
Este projeto utiliza um recurso de seguran√ß√£o do terraform para utiliza√ß√£o de scripts python que ser√£o utilzados nesse projeto e ser√£o enviados para o bucket-s3.
O bucket-s3 onde os scripts python ficar√£o armazenados ser√° destru√≠do ao final deste projeto.

#### **`filemd5` no Terraform - Explica√ß√£o Detalhada**
A fun√ß√£o **`filemd5`** no Terraform √© usada para calcular o **hash MD5** do conte√∫do de um arquivo. O MD5 (Message Digest Algorithm 5) √© um algoritmo de hash criptogr√°fico que gera um valor de 128 bits (32 caracteres hexadecimais) a partir de uma entrada, permitindo verificar altera√ß√µes no conte√∫do de um arquivo.

---

#### **1.4.1.1.üìå Sintaxe da Fun√ß√£o**
```hcl
filemd5(path)
```
- **`path`**: Caminho do arquivo no sistema de arquivos local.
- Retorna uma **string hexadecimal** representando o hash MD5 do conte√∫do do arquivo.

---

#### **1.4.1.2.üìå Exemplo B√°sico**
Se tivermos um arquivo chamado `config.yaml`, podemos calcular seu hash MD5 da seguinte maneira:

```hcl
output "config_md5" {
  value = filemd5("config.yaml")
}
```
#### **1.4.1.3. Sa√≠da esperada no Terraform Apply:**
```bash
config_md5 = "d41d8cd98f00b204e9800998ecf8427e"
```
Este hash muda sempre que o conte√∫do do arquivo `config.yaml` √© alterado.

---

#### **1.4.1.2. üìå Para que serve `filemd5` no Terraform?**
#### **1.4.1.2.1. Detectar mudan√ßas em arquivos**
Se um arquivo for modificado, seu hash MD5 tamb√©m ser√° alterado. Isso pode ser √∫til para:
- Identificar altera√ß√µes de arquivos de configura√ß√£o.
- Criar regras para acionar a recria√ß√£o de recursos no Terraform.

---

#### **1.4.1.2.1.2. For√ßar a recria√ß√£o de recursos quando um arquivo muda**
O Terraform pode n√£o detectar mudan√ßas em arquivos usados em um recurso. Podemos usar `filemd5` dentro da op√ß√£o **`triggers`** de um recurso para for√ßar sua atualiza√ß√£o quando o arquivo for alterado.

#### **Exemplo: For√ßando atualiza√ß√£o de um servidor quando um script muda**
```hcl
resource "aws_instance" "example" {
  ami           = "ami-12345678"
  instance_type = "t2.micro"

  user_data = file("setup.sh")

  lifecycle {
    ignore_changes = [user_data]
  }

  triggers = {
    script_hash = filemd5("setup.sh")
  }
}
```
**O que acontece aqui?**
- O Terraform calcular√° o hash MD5 do arquivo `setup.sh`.
- Se o conte√∫do de `setup.sh` mudar, o hash tamb√©m muda.
- Isso faz com que o recurso **`aws_instance.example`** seja recriado automaticamente.

---

#### **1.4.1.3. Compara√ß√£o de arquivos para controle de vers√µes**
Podemos comparar o hash de dois arquivos diferentes para verificar se possuem o mesmo conte√∫do.

```hcl
output "comparison" {
  value = filemd5("config_old.yaml") == filemd5("config_new.yaml")
}
```
Se os arquivos forem id√™nticos, o output ser√° `true`, caso contr√°rio, `false`.

---

#### **1.4.1.4.üìå Limita√ß√µes**
1. **Apenas arquivos locais**: `filemd5` s√≥ pode ser usado em arquivos armazenados localmente no ambiente onde o Terraform est√° sendo executado.
2. **N√£o detecta mudan√ßas em arquivos remotos**: Se o arquivo estiver em um S3 ou GitHub, `filemd5` n√£o funcionar√° diretamente.
3. **MD5 n√£o √© seguro para criptografia**: Embora seja √∫til para detectar mudan√ßas, o MD5 n√£o deve ser usado para fins de seguran√ßa (exemplo: armazenamento de senhas).

---

#### **1.4.1.5.üìå Alternativas e Complementos**
- **`filesha256("file.txt")`** ‚Üí Se precisar de um hash mais seguro, use SHA-256 em vez de MD5.
- **`file("arquivo.txt")`** ‚Üí Para obter o conte√∫do de um arquivo como string.

---

#### **1.4.1.6.üìå Conclus√£o**
A fun√ß√£o **`filemd5`** √© muito √∫til no Terraform para rastrear mudan√ßas em arquivos e garantir que recursos sejam atualizados quando necess√°rio. Usando essa fun√ß√£o de forma estrat√©gica, √© poss√≠vel melhorar a automa√ß√£o e a confiabilidade da infraestrutura.

## **2. Este projeto utilizar√° armazenamento de dados em formatp parquet**
#### **2.1.üìå Por que usar arquivos Parquet para armazenamento de dados?**

O **Parquet** √© um formato de armazenamento de dados amplamente utilizado em sistemas de Big Data por suas vantagens de desempenho e efici√™ncia. Ele foi projetado para processamento anal√≠tico e otimizado para leitura r√°pida e compacta√ß√£o eficiente.

#### **2.2.üîπ Principais Benef√≠cios do Parquet**

#### üöÄ 1. Alto Desempenho na Leitura
- Formato **colunar**, permitindo leitura seletiva de colunas, reduzindo I/O.
- Ideal para **consultas anal√≠ticas** e **agrega√ß√µes**.

#### üìâ 2. Melhor Compress√£o e Efici√™ncia de Armazenamento
- **Compress√£o eficiente** por colunas (Snappy, Gzip, ZSTD).
- **Menos espa√ßo em disco** comparado a CSV e JSON.

#### ‚ö° 3. Suporte a Tipagem e Esquema R√≠gido
- **Mant√©m tipos de dados** (inteiros, floats, strings, etc.).
- **Evita parsing e convers√µes desnecess√°rias**, tornando a leitura mais r√°pida.

#### üîÑ 4. Integra√ß√£o com Ferramentas de Big Data
- Compat√≠vel com **Apache Spark, Hive, Presto, AWS Athena, Google BigQuery**, entre outros.
- Ideal para **Data Lakes** e processamento distribu√≠do.

#### üõ† 5. Melhor Manuseio de Dados Estruturados
- **Suporte a metadados e parti√ß√µes**.
- Permite leitura eficiente mesmo em **grandes volumes de dados**.

#### **2.3. üéØ Quando Usar o Parquet?**
‚úÖ Data Lakes e **armazenamento eficiente em cloud** (AWS S3, GCS, Azure).  
‚úÖ Consultas anal√≠ticas e **Big Data**.  
‚úÖ Redu√ß√£o de custos com **armazenamento e processamento**.  
‚úÖ Integra√ß√£o com **ferramentas de BI e Machine Learning**.  

#### **2.4.üèÅ Conclus√£o**
O formato **Parquet** oferece **melhor desempenho, menor custo de armazenamento e integra√ß√£o perfeita com ferramentas de Big Data**. Se voc√™ trabalha com **grandes volumes de dados**, esse √© o formato ideal para otimizar seu fluxo de trabalho.



## **3. Como executar este projeto** 


### 3.1. Configura√ß√£o Inicial

1. Abra o terminal ou prompt de comando.
2. Navegue at√© a pasta onde voc√™ colocou os arquivos do projeto.
   - **Nota:** Evite usar espa√ßos ou acentos no nome das pastas.

### 3.2. Constru√ß√£o da Imagem Docker

Execute o comando abaixo para criar a imagem Docker:
```sh
docker build -t bamr-terraform-image:projeto2 .
```

### 3.3. Cria√ß√£o do Container Docker

Execute o comando abaixo para criar o container Docker:
```sh
docker run -dit --name bamr-p2 -v ./IaC:/iac bamr-terraform-image:p2 /bin/bash
```

**Nota:** No Windows, substitua `./IaC` pelo caminho completo da pasta. Exemplo:

### 3.4. Verifica√ß√£o das Vers√µes

Verifique se o Terraform e o AWS CLI est√£o instalados corretamente com os seguintes comandos:
```sh
terraform version
aws --version
```

---

## Configura√ß√£o do Projeto

### 1. Editar Arquivos de Configura√ß√£o

- Edite os arquivos `config.tf` e `terraform.tfvars` e insira seu **ID da AWS** onde indicado.
- No script `projeto2.py`, adicione seu **ID da AWS** e suas **chaves AWS** onde indicado.

### 2. Criar Bucket S3 Manualmente

Antes de executar o Terraform, crie manualmente o bucket S3 com o nome:
```sh
bamr-dsa-p2-terraform-<id-aws>
```
**Substitua `<id-aws>` pelo seu ID da AWS.** \
**bamr-dsa-p2-terraform √© apenas a sugest√£o do meu projeto.**

### 3. Inicializa√ß√£o e Deploy do Terraform

Execute os seguintes comandos:
```sh
terraform init
terraform apply
```

### 4. Monitoramento do Pipeline

- Acompanhe a execu√ß√£o do pipeline pela **interface da AWS**, conforme demonstrado nas aulas.

---

## Conclus√£o

Parab√©ns! Voc√™ configurou e implantou o ambiente com sucesso. üöÄ


