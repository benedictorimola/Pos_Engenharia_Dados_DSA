# Pós-Graduação em Engenharia de Dados Data Science Academy


A [Pós-Graduação em Engenharia De Dados Lato Sensu da DSA](https://www.datascienceacademy.com.br/bundle/pos-graduacao-em-engenharia-de-dados) é um programa de extensão de especialização na área de dados. \
O programa é reconhecido pelo MEC e oferece título de especialista, com certificado final emitido pela [Faculdade Vincit](https://www.faculdadevincit.edu.br/) em parceria com a [Data Science Academy](https://www.datascienceacademy.com.br/home).


## Disciplinas 
### - [Infraestrutura Como Código com Terraform, AWS, Azure e Databricks](https://www.datascienceacademy.com.br/course/infraestrutura-como-codigo-com-terraform-aws-azure-e-databricks) 
__STATUS: EM ANDAMENTO__ \
Carga horária: 72h \
Logbook das Principais Atividades Práticas \
Lab 1 - IaC Stack - Automatizando a Infraestrutura de Instâncias EC2 na Nuvem AWS com Terraform \
Lab 2 - IaC Stack - Automatizando a Infraestrutura na Nuvem AWS com Variáveis no Terraform \
Lab 3 - IaC Stack - Usando Terraform Provisioners e Outras Tarefas de Automação \
Lab 4 - Deploy de Infraestrutura e API Para Aplicação de Data Science na AWS com Terraform \
Lab 5 - IaC com Terraform Para Deploy de Aplicação Web em Container Docker no AWS ECS \
Projeto 1 - Automatizando Infraestrutura de Processamento de Dados com AWS EMR e Apache Flink \
Projeto 2 - Deploy do Stack de Treinamento Distribuído de Machine Learning com PySpark no Amazon EMR \
Projeto 3 - Deploy do Stack de Infraestrutura de Dados no Azure com Terraform \
Projeto 4 - AWS e Azure Multi-Cloud Deploy com Terraform \
Projeto 5 - Databricks Cluster Deploy com Terraform Para Processamento Distribuído

### - [Modelagem, Implementação e Governança de Data Warehouses](https://www.datascienceacademy.com.br/course/modelagem-implementacao-e-governanca-de-data-warehouses)
__STATUS: NÃO INICIADA__ \
Carga horária: 80h \
Logbook das Principais Atividades Práticas \
Lab 1 - Automação da Infraestrutura de Consultas SQL com Terraform e BigQuery no Google Cloud Platform \
Lab 2 - Usando o ChatGPT Para Construir Um Modelo Dimensional de Forma Segura \
Lab 3 - Airbyte e SQL Para ETL no Data Warehouse em Ambiente Local \
Lab 4 - Processo de Governança e Qualidade de Dados no Data Warehouse \
Lab 5 - Migração de Data Warehouse Local Para a Nuvem \
Estudo de Caso - O Que é e Como Implementar ETL Reverso? \
Projeto 1 - Modelagem e Implementação de Um Data Warehouse Local \
Projeto 2 - Modelagem e Implementação de Data Warehouse na Nuvem com Amazon Redshift e Terraform

### - [Engenharia de Dados com Airbyte, DBT e SQL](https://www.datascienceacademy.com.br/course/engenharia-de-dados-com-airbyte-dbt-e-sql)
__STATUS: NÃO INICIADA__ \
Carga horária: 96h \
Logbook das Principais Atividades Práticas \
Lab 1 - Movimentação de Dados Entre Bancos de Dados com Airbyte \
Lab 2 - Construindo Pipeline EL(T) com Change Data Capture (CDC) \
Lab 3 - Carga e Sincronização Incremental de Dados com Airbyte \
Lab 4 - Plano de Execução e Otimização de Consultas em Pipelines de Engenharia de Dados \
Lab 5 - Modelagem de Dados Para Engenharia de Dados em Sistemas de IA \
Lab 6 - Deploy e Re-Deploy do Primeiro Modelo com DBT \
Lab 7 - Criação de Macros, Refatoramento e Deploy em Produção com DBT \
Lab 8 - Automação de Testes de Modelos de Dados no DBT \
Lab 9 - Analytics Engineering e Linhagem de Dados com Python, DBT, BigQuery e Looker Studio \
Projeto Final de Integração Entre Airbyte, DBT e SQL

### - [Armazenamento e Gestão de Dados com Data Lake e Data Lakehouse](https://www.datascienceacademy.com.br/course/armazenamento-e-gestao-de-dados-com-data-lake-e-data-lakehouse)
__STATUS: NÃO INICIADA__ \
Carga Horária: 86h \
Logbook das Principais Atividades Práticas \
Lab 1 - Plano de Custo Para Implementar Data Lakes e Data Lakehouses em Diferentes Cenários \
Lab 2 - Design e Implementação de Data Lake Local Para Armazenamento e Processamento Distribuído \
Lab 3 - Design e Implementação de Data Lake na Nuvem com IaC e Terraform \
Lab 4 - Linhagem, Observabilidade, Qualidade, Enriquecimento e Governança de Dados no Data Lake \
Lab 5 - Trabalhando com Databricks Para Construção de Catálogo Unificado de Dados \
Lab 6 - Operações CRUD e Time Travel com Delta Lake \
Lab 7 - Delta Live Tables SQL Pipeline e Integração de Dados Batch e Streaming \
Projeto de Implementação de Data Lakehouse com Databricks e Delta Lake

### - [PySpark e Apache Kafka Para Processamento de Dados em Batch e Streaming](https://www.datascienceacademy.com.br/course/pyspark-e-apache-kafka-para-processamento-de-dados-em-batch-e-streaming)
__STATUS: NÃO INICIADA__ \
Carga horária: 90h \
Logbook das Principais Atividades Práticas \
Projeto 1 - Pipeline PySpark Para Extrair, Transformar e Carregar Arquivos JSON em Banco de Dados \
Projeto 2 - 50 Scripts de Otimização de Processamento e Análise de Dados em Cluster Spark \
Projeto 3 - Pipeline de Limpeza e Transformação Para Aplicações de IA com PySpark SQL \
Projeto 4 - Processamento e Análise de Dados em Tempo Real com PySpark Streaming \
Projeto 5 - Extração, Processamento e Armazenamento de Dados em Tempo Real com Kafka e Spark Streaming \
Projeto 6 - Kafka Streams Para Agregação de Dados em Tempo Real \
Projeto 7 - Stack de Extração, Transformação e Carga de Dados com Kafka, PySpark e Data Lakehouse \
Projeto 8 - Simulação de Erros e Recuperação de Falhas em Cluster Kafka
